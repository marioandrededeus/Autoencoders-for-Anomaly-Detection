# Autoencoders-for-Anomaly-Detection
Google Colab Notebook for Anomaly Detection for Autoencoders


This notebook  aims to test the potential of autoencoders in the realm of anomaly detection. It aims to build an autoencoder that has been trained upon the healthy and normal operation conditions of an engine, so that when it views input data that contains anomalies, it produces a high reconstruction error that can be used to flag the input as anomalous. If you'd like to view the code explanation, you can do so here:


Dataset and Research Article:
- Research Article: https://www.researchgate.net/publication/375511821_EngineFaultDB_A_Novel_Dataset_for_Automotive_Engine_Fault_Classification_and_Baseline_Results
- Dataset: https://github.com/Leo-Thomas/EngineFaultDB

Below is an **attractive, portfolio-grade README.md** written in **clear technical English**, suitable for GitHub, recruiters, and technical reviewers.
It positions the project as **applied anomaly detection with an interactive web app**, not just a notebook experiment.

You can copy-paste this directly as your `README.md`.

---

# Anomaly Detection with Autoencoders

### Interactive Streamlit Web App for Synthetic Normal & Anomalous Data

## Overview

This project demonstrates **anomaly detection using deep autoencoders**, combining **offline model training** with an **interactive Streamlit web application** for real-time simulation and visualization.

The solution allows users to:

* Generate **synthetic normal or anomalous data** on demand
* Detect anomalies based on **reconstruction error**
* Visually compare new samples against the **training data distribution**
* Understand model behavior through **PCA-based scatter plots**

This repository is designed as a **hands-on portfolio project**, with strong emphasis on **interpretability, reproducibility, and practical deployment**.

---

## Problem Statement

In many real-world scenarios—such as **industrial monitoring, predictive maintenance, fraud detection, and process optimization**—anomalous events are rare and poorly labeled.

Autoencoders provide an effective **unsupervised learning approach**, where:

* The model is trained only on **normal behavior**
* Anomalies are detected when reconstruction error exceeds a defined threshold

This project illustrates that concept end-to-end, from data generation to interactive inference.

---

## Solution Architecture

**Offline phase**

* Train an autoencoder on normal data
* Define an anomaly threshold based on reconstruction error

**Online phase (Web App)**

* Generate new synthetic samples (normal or anomalous)
* Compute reconstruction error
* Classify the sample
* Visualize its position relative to training data

```
User Input
   ↓
Synthetic Data Generator
   ↓
Autoencoder Inference
   ↓
Reconstruction Error
   ↓
Threshold Comparison
   ↓
Anomaly Decision + Visualization
```

---

## Project Structure

```
anomaly-detection-autoencoder/
│
├── models/
│   └── autoencoder.h5          # Trained autoencoder
│
├── data/
│   └── train_data.csv          # Normal training data
│
├── src/
│   ├── data_generator.py       # Normal / anomalous data generation
│   ├── model_utils.py          # Inference & reconstruction error
│   └── visualization.py        # PCA-based visualization
│
├── app.py                      # Streamlit web application
├── requirements.txt
└── README.md
```

This structure reflects **production-oriented separation of concerns**, rather than a single monolithic notebook.

---

## Synthetic Data Generation

The application generates two types of samples:

### Normal Data

* Sampled from the same distribution as the training data
* Represents expected system behavior

### Anomalous Data

* Generated by shifting the mean and increasing variance
* Simulates out-of-distribution or faulty behavior

This approach enables **controlled testing** of the anomaly detection pipeline.

---

## Anomaly Detection Logic

* The autoencoder learns to reconstruct **normal patterns**
* Reconstruction error is computed as:

[
\text{MSE}(x, \hat{x})
]

* A sample is classified as **anomalous** if:

[
\text{Reconstruction Error} > \text{Threshold}
]

The threshold can be tuned based on operational risk tolerance.

---

## Visualization Strategy

Since the dataset may have many features, **PCA (Principal Component Analysis)** is used to project:

* Training data
* Newly generated sample

into a **2D scatter plot**, enabling intuitive visual comparison.

This improves **model interpretability**, which is critical in industrial and business contexts.

---

## Running the Project Locally

### 1. Clone the repository

```bash
git clone https://github.com/your-username/anomaly-detection-autoencoder.git
cd anomaly-detection-autoencoder
```

### 2. Create a virtual environment (recommended)

```bash
conda create -n anomaly-autoencoder python=3.9 -y
conda activate anomaly-autoencoder
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Launch the Streamlit app

```bash
streamlit run app.py
```

The app will open automatically in your browser.

---

## Example Use Cases

* Industrial process monitoring
* Predictive maintenance
* Sensor fault detection
* Financial or transactional anomaly detection
* Proof-of-concept for unsupervised ML pipelines

---

## Key Learnings Demonstrated

* Unsupervised anomaly detection with deep learning
* Reconstruction-error-based scoring
* Synthetic data simulation for testing
* Model interpretability via PCA
* Transition from notebook to deployable web app
* Clean project structure aligned with MLOps principles

---

## Possible Extensions

* Time-series autoencoders (LSTM / GRU)
* Variational Autoencoders (VAE)
* User-uploaded CSV data
* Dynamic threshold tuning
* Model monitoring dashboards
* Cloud deployment (Streamlit Cloud / Azure Web App)

---

## Author

Developed as a **personal portfolio project** to demonstrate applied machine learning, anomaly detection, and interactive ML applications.

If you want, I can next:

* Customize this README for **industrial / B2B audiences**
* Add an **architecture diagram**
* Rewrite it to match **Data Scientist vs. ML Engineer positioning**
* Prepare a **LinkedIn project description**


